{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b00d1bd1-e2e0-4f71-a873-abe8c8b03b1f",
   "metadata": {
    "id": "b00d1bd1-e2e0-4f71-a873-abe8c8b03b1f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p76121194/miniconda3/envs/dl_hw1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "\n",
    "from torch.nn import init\n",
    "from torch.nn.modules.utils import _pair\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from thop import profile, clever_format\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67dd633a-ba38-4d5b-919f-a9d740b05f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cafd4235-5d5c-4d34-be4d-aed1d42d25f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, c_dim, hidden_dim, nof_kernels, out_channel, in_channel):\n",
    "        super().__init__()\n",
    "        self.nof_kernels = nof_kernels\n",
    "        self.out_channel = out_channel\n",
    "        self.in_channel = in_channel\n",
    "        self.global_pooling = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Flatten())\n",
    "        self.to_scores = nn.Sequential(nn.Linear(in_channel, hidden_dim),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       nn.Linear(hidden_dim, nof_kernels*out_channel*in_channel)\n",
    "                                      )\n",
    "\n",
    "    def forward(self, x, temperature=1):\n",
    "        out = self.global_pooling(x)\n",
    "        scores = self.to_scores(out)\n",
    "        scores = scores.reshape(x.shape[0], self.nof_kernels, self.out_channel, self.in_channel)\n",
    "        return F.softmax(scores / temperature, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03bd3a5-273e-48d7-bc94-0e1ae51cc232",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicConv2d(nn.Module):\n",
    "    def __init__(self, nof_kernels, reduce, in_channels, out_channels, kernel_size,\n",
    "                 stride=1, padding=0, dilation=1, bias=True):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.conv_args = {'stride': stride, 'padding': padding, 'dilation': dilation}\n",
    "        self.nof_kernels = nof_kernels\n",
    "        self.kernel_size = _pair(kernel_size)\n",
    "        # kernels_weights: (nof_kernels, out_channels, in_channels, *self.kernel_size)\n",
    "        self.kernels_weights = nn.Parameter(torch.Tensor(\n",
    "            nof_kernels, out_channels, in_channels, *self.kernel_size), requires_grad=True)\n",
    "        if bias:\n",
    "            self.kernels_bias = nn.Parameter(torch.Tensor(out_channels), requires_grad=True)\n",
    "        else:\n",
    "            self.register_parameter('kernels_bias', None)\n",
    "\n",
    "        self.attention = AttentionLayer(3, max(8, in_channels // reduce), nof_kernels, out_channels, in_channels)\n",
    "        self.initialize_parameters()\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        for i_kernel in range(self.nof_kernels):\n",
    "            init.kaiming_uniform_(self.kernels_weights[i_kernel], a=math.sqrt(5))\n",
    "        if self.kernels_bias is not None:\n",
    "            bound = 1 / math.sqrt(self.kernels_weights[0, 0].numel())\n",
    "            nn.init.uniform_(self.kernels_bias, -bound, bound)\n",
    "\n",
    "    def forward(self, x, temperature=1):\n",
    "        # x: (batch_size , in_channels , H , W)\n",
    "        batch_size = x.shape[0]\n",
    "        # alphas: (batch_size , nof_kernels, self.out_channels, self.in_channels)\n",
    "        alphas = self.attention(x, temperature)\n",
    "\n",
    "        # self.kernels_weights.unsqueeze(0): (1, nof_kernels, out_channels, in_channels, self.kernel_size, self.kernel_size)\n",
    "        # alphas.view(): (batch_size , nof_kernels, self.out_channels, self.in_channels, 1, 1)\n",
    "        # agg_weights: (batch_size, self.out_channels, self.in_channels, self.kernel_size, self.kernel_size)\n",
    "        agg_weights = torch.sum(\n",
    "            torch.mul(self.kernels_weights.unsqueeze(0), alphas.view(batch_size, self.nof_kernels, self.out_channels, self.in_channels, 1, 1)), dim=1)\n",
    "\n",
    "        # agg_weights: (batch_size * out_channels , in_channels, kernel_size, kernel_size)\n",
    "        agg_weights = agg_weights.view(-1, *agg_weights.shape[-3:])\n",
    "\n",
    "\n",
    "        if self.kernels_bias is not None:\n",
    "            agg_bias = self.kernels_bias.repeat(batch_size)\n",
    "        else:\n",
    "            agg_bias = None\n",
    "\n",
    "        x_grouped = x.view(1, -1, *x.shape[-2:])  # (1 , batch_size*out_c , H , W)\n",
    "        #   out: (1 , batch_size*out_C , H' , W')\n",
    "        out = F.conv2d(x_grouped, agg_weights, agg_bias, groups=batch_size,\n",
    "                        **self.conv_args)\n",
    "        # out: (batch_size , out_channels , H' , W')\n",
    "        out = out.view(batch_size, -1, *out.shape[-2:])\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a331090-a425-40af-848c-51af5a7d6637",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicCNN(nn.Module):\n",
    "    def __init__(self, num_classes=50, nof_kernels=4):\n",
    "        super(DynamicCNN, self).__init__()\n",
    "        self.dycnn = nn.ModuleList([\n",
    "            DynamicConv2d(nof_kernels=nof_kernels, reduce=4, in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1, dilation=1, bias=True),\n",
    "                    DynamicConv2d(nof_kernels=nof_kernels, reduce=4, in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1, dilation=1, bias=True),\n",
    "                      DynamicConv2d(nof_kernels=nof_kernels, reduce=4, in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, dilation=1, bias=True),\n",
    "                      DynamicConv2d(nof_kernels=nof_kernels, reduce=4, in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, dilation=1, bias=True)\n",
    "                     ])\n",
    "        self.norm =  nn.ModuleList([nn.BatchNorm2d((2**i) * 32) for i in range(4)])\n",
    "        self.act = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2, 0)\n",
    "\n",
    "            \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*8*8, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, temperature=1):\n",
    "        out = x\n",
    "        for i in range(4):\n",
    "            out = self.dycnn[i](out, temperature=temperature)\n",
    "            out = self.norm[i](out)\n",
    "            out = self.act(out)\n",
    "            out = self.pool(out)\n",
    "            \n",
    "        out = out.view(out.size()[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079064bd-bea3-4ce6-ba89-0014fad6fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=50):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, 1, 1), # [32, 128, 128]\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [32, 64, 64]\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, 1, 1), # [64, 64, 64]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [64, 32, 32]\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, 1), # [128, 32, 32]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [128, 16, 16]\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, 1, 1), # [256, 16, 16]\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),       # [256, 8, 8]\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*8*8, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, temperature=1):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aca5383e-bdc2-4111-bdb1-1559a45bb702",
   "metadata": {
    "id": "aca5383e-bdc2-4111-bdb1-1559a45bb702"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, x, y=None, transform=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        if y is not None:\n",
    "            self.y = torch.LongTensor(y)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, index):\n",
    "        X = self.x[index]\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        if self.y is not None:\n",
    "            Y = self.y[index]\n",
    "            return X, Y\n",
    "        else:\n",
    "            return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c4b9ecf-81b1-497d-83a9-fcb1b58d03d0",
   "metadata": {
    "id": "6c4b9ecf-81b1-497d-83a9-fcb1b58d03d0"
   },
   "outputs": [],
   "source": [
    "def random_channel(images, channel_combinations):\n",
    "    channel_dict = {i:c for i,c in enumerate(channel_combinations)}\n",
    "    new_images = []\n",
    "    n = len(list(channel_dict.keys()))\n",
    "    channels = []\n",
    "    for i, image in enumerate(images):\n",
    "        channel_idx = i % n\n",
    "        # 修改通道\n",
    "        if channel_dict[channel_idx] == 'BGR':\n",
    "            img = image[:, :, :]\n",
    "        elif channel_dict[channel_idx] == 'GR':\n",
    "            img = image[:, :, 1:]\n",
    "        elif channel_dict[channel_idx] == 'BG':\n",
    "            img = image[:, :, :2]\n",
    "        elif channel_dict[channel_idx] == 'R':\n",
    "            img = image[:, :, 2:3]\n",
    "        elif channel_dict[channel_idx] == 'G':\n",
    "            img = image[:, :, 1:2]\n",
    "        elif channel_dict[channel_idx] == 'B':\n",
    "            img = image[:, :, 0:1]\n",
    "        else:\n",
    "            print(\"error\")\n",
    "        new_images.append(img)\n",
    "        channels.append(channel_dict[channel_idx])\n",
    "    return channels, new_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f28a9c5-be30-441e-abe6-8d5bf30c1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name, nof_kernels=4):\n",
    "    model = None\n",
    "    if model_name == \"DynamicCNN\":\n",
    "        model = DynamicCNN(num_classes=50, nof_kernels=nof_kernels)\n",
    "    elif model_name == \"base_model\":\n",
    "        model = SimpleCNN(num_classes=50)\n",
    "        \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "274ca17c-2a38-4461-b261-cdcb8c1d161e",
   "metadata": {
    "id": "274ca17c-2a38-4461-b261-cdcb8c1d161e"
   },
   "outputs": [],
   "source": [
    "def load_img(f):\n",
    "    shapes = []\n",
    "    f=open(f)\n",
    "    lines=f.readlines()\n",
    "    imgs, lab=[], []\n",
    "    for i in range(len(lines)):\n",
    "        fn, label = lines[i].split(' ')\n",
    "        im1=cv2.imread(fn)\n",
    "\n",
    "        if im1.shape[2] not in shapes:\n",
    "            shapes.append(im1.shape[2])\n",
    "\n",
    "        imgs.append(im1)\n",
    "        lab.append(int(label))\n",
    "\n",
    "    \n",
    "    lab= np.asarray(lab, np.uint8)\n",
    "    \n",
    "    return imgs, lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b56c455f-a089-46f5-ae1b-86b24d72adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_input(channels, images, img_size):\n",
    "    channel_map = {\"BGR\": torch.tensor([1,1,1]), \"BG\":torch.tensor([1,1,0]), \"GR\":torch.tensor([0,1,1]), \"B\":torch.tensor([1,0,0]), \"G\":torch.tensor([0,1,0]), \"R\":torch.tensor([0,0,1])}\n",
    "    x = np.zeros((len(images), img_size, img_size, 3), dtype=np.uint8)\n",
    "    c = np.zeros((len(images), 3),  dtype=np.uint8)\n",
    "    for i, img in enumerate(images):\n",
    "        # 3通道圖片\n",
    "        img_3channel = np.zeros((img_size, img_size, 3), dtype=img.dtype)\n",
    "        \n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "\n",
    "        if channels[i] == \"B\":\n",
    "            img_3channel[:, :, 0] = img \n",
    "        elif channels[i] == \"G\":\n",
    "            img_3channel[:, :, 1] = img \n",
    "        elif channels[i] == \"R\":\n",
    "            img_3channel[:, :, 2] = img \n",
    "        elif channels[i] == \"BGR\":\n",
    "            img_3channel = img\n",
    "        elif channels[i] == \"BG\":\n",
    "            # 合併成三通道圖像\n",
    "            img_3channel[:, :, :2] = img  # 前兩個通道保持不變\n",
    "        elif channels[i] == \"GR\":\n",
    "            img_3channel[:, :, 1:] = img  # 後兩個通道保持不變\n",
    "        else:\n",
    "            print(\"error\")\n",
    "        x[i, :, :, :] = img_3channel\n",
    "        c[i, :] = channel_map[channels[i]]\n",
    "    return c, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4948f163-08bc-48d3-8d20-449b23071e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_complexity(model, inputs):\n",
    "    # 计算FLOPs和参数量\n",
    "    flops, params = profile(model, inputs=(inputs,))\n",
    "    flops, params = clever_format([flops, params], \"%.3f\")\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "879b291b-2ea9-4182-9366-0b15c78819d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, eval_time, num_epoch, n_train, n_val, temperature, lr, device):\n",
    "    # print(\"--4--\")\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # model = model.to(device)\n",
    "\n",
    "    loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr) # optimizer 使用 Adam\n",
    "\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        print(epoch)\n",
    "        \n",
    "        epoch_start_time = time.time()\n",
    "        train_acc = 0.0\n",
    "        train_loss = 0.0\n",
    "        val_acc = 0.0\n",
    "        val_loss = 0.0\n",
    "\n",
    "        model.train() # 確保 model 是在 train model (開啟 Dropout 等...)\n",
    "        for i, data in enumerate(train_loader):\n",
    "            optimizer.zero_grad() # 用 optimizer 將 model 參數的 gradient 歸零\n",
    "            \n",
    "            train_pred = model(data[0].to(device), temperature=temperature) # 利用 model 得到預測的機率分佈 這邊實際上就是去呼叫 model 的 forward 函數\n",
    "            batch_loss = loss(train_pred, data[1].to(device)) # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\n",
    "            batch_loss.backward() # 利用 back propagation 算出每個參數的 gradient\n",
    "            optimizer.step() # 以 optimizer 用 gradient 更新參數值\n",
    "\n",
    "            train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "            train_loss += batch_loss.item()\n",
    "\n",
    "        if epoch % eval_time == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(val_loader):\n",
    "                    val_pred = model(data[0].to(device), temperature=temperature)\n",
    "                    batch_loss = loss(val_pred, data[1].to(device))\n",
    "\n",
    "                    val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "                    val_loss += batch_loss.item()\n",
    "\n",
    "                # 將結果 print 出來\n",
    "                print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n",
    "                    (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n",
    "                     train_acc/n_train, train_loss/n_train, val_acc/n_val, val_loss/n_val))\n",
    "\n",
    "                wandb.log({\"Train/epoch\": epoch,\n",
    "                            \"Train/acc\": train_acc/n_train,\n",
    "                           \"Train/loss\": train_loss/n_train,\n",
    "                           \"Val/epoch\": epoch,\n",
    "                           \"Val/acc\": val_acc/n_val,\n",
    "                           \"Val/loss\": val_loss/n_val,\n",
    "                          })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "398843e5-8cdb-44e7-8c10-91147241758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, n_test, temperature, device):\n",
    "    model.eval()\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # model = model.to(device)\n",
    "    loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\n",
    "    \n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    test_acc = 0.0\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            test_pred = model(data[0].to(device), temperature=temperature)\n",
    "            batch_loss = loss(test_pred, data[1].to(device))\n",
    "            test_loss += batch_loss.item()\n",
    "\n",
    "            _, preds = torch.max(test_pred, 1)\n",
    "            all_labels.extend(data[1].cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "        recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "        print(\"--------Test result-------------\")\n",
    "        print(f'Accuracy: {accuracy:.4f}')\n",
    "        print(f'Precision: {precision:.4f}')\n",
    "        print(f'Recall: {recall:.4f}')\n",
    "        print(f'F1-score: {f1:.4f}')\n",
    "        print(f'Loss: {test_loss//n_test:.4f}')\n",
    "        print(\"--------------------------------\")\n",
    "\n",
    "        wandb.log({\"Test/Accuracy\": accuracy,\n",
    "                   \"Test/Precision\": precision,\n",
    "                   \"Test/Recall\": recall,\n",
    "                   \"Test/F1-score\": f1,\n",
    "                  \"Test/Loss\": test_loss/n_test,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712eff19-db2a-4a10-8906-548ec2d6242d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6662e4f1-ed9e-45ce-bdb0-ae66f253f698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nof_kernel\n",
    "def experiment_5_1():\n",
    "    # 超參數\n",
    "    #############\n",
    "    eval_time = 1\n",
    "    num_epoch = 50\n",
    "    num_classes = 30\n",
    "    img_size = 144\n",
    "    input_size = 128\n",
    "    batch_size = 128\n",
    "    lr = 0.001\n",
    "    model_name= 'DynamicCNN'\n",
    "    temperature = 1\n",
    "    #############\n",
    "    set_seed(42)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    x, y = load_img('train.txt')\n",
    "    vx, vy = load_img('val.txt')\n",
    "    tx, ty = load_img('test.txt')\n",
    "    print(\"--1--\")\n",
    "    # 產生隨機組合通道數的圖片\n",
    "    channel_combinations = ['BGR','GR','BG','R','G','B']\n",
    "    c, x_new = random_channel(x, channel_combinations)\n",
    "    vc, vx_new = random_channel(vx, channel_combinations)\n",
    "    tc, tx_new = random_channel(tx, channel_combinations)\n",
    "    del x, vx, tx\n",
    "    print(\"--2--\")\n",
    "    # 填補成三通道\n",
    "    c, x_resize = resize_input(c, x_new, img_size=img_size)\n",
    "    vc, vx_resize = resize_input(vc, vx_new, img_size=img_size)\n",
    "    tc, tx_resize = resize_input(tc, tx_new, img_size=img_size)\n",
    "    del x_new, vx_new, tx_new\n",
    "    print(\"--3--\")\n",
    "    # 定義transform\n",
    "    # training 時做 data augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((img_size, img_size)),  # 縮放\n",
    "        transforms.RandomRotation(degrees=30),  # 旋轉\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 平移\n",
    "        transforms.RandomCrop(input_size),  # 隨機裁剪\n",
    "        transforms.RandomHorizontalFlip(),  # 水平翻轉\n",
    "        transforms.ToTensor(),  # 轉換為Tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 標準化\n",
    "\n",
    "    ])\n",
    "    # testing 時不需做 data augmentation\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((img_size, img_size)),  # 縮放\n",
    "        transforms.CenterCrop(input_size),  # 中心裁剪\n",
    "        transforms.ToTensor(),  # 轉換為Tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 標準化\n",
    "    ])\n",
    "    # data loader\n",
    "    train_set = ImgDataset(x_resize, y, train_transform)\n",
    "    val_set = ImgDataset(vx_resize, vy, test_transform)\n",
    "    test_set = ImgDataset(tx_resize, ty, test_transform)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, worker_init_fn=lambda _: np.random.seed(42), num_workers=4)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    del x_resize, vx_resize, tx_resize\n",
    "    \n",
    "    print(\"--4--\")\n",
    "    wandb.login()\n",
    "    for nof_kernels in [1, 3, 5, 7]:\n",
    "        print(\"-----number of kernels = \"+str(nof_kernels)+\"-----\")\n",
    "        # create model\n",
    "        model = create_model(model_name, nof_kernels=nof_kernels).to(device)\n",
    "        # 測FLOPs、params\n",
    "        # 创建输入张量\n",
    "        inputs = torch.randn(1, 3, input_size, input_size)\n",
    "        calc_complexity(model, inputs.to(device))\n",
    "        \n",
    "        run = wandb.init(\n",
    "        # Set the project where this run will be logged\n",
    "        project=\"task1_experiment_5_1\",\n",
    "        name=model_name+\"_nof_kernels=\"+str(nof_kernels),\n",
    "        config={\n",
    "            \"model\": model_name,\n",
    "            \"learning_rate\": lr,\n",
    "            \"epochs\": num_epoch,\n",
    "            \"input_size\": input_size,\n",
    "            \"nof_kernels\": nof_kernels,\n",
    "        },)\n",
    "        wandb.define_metric(\"Train/epoch\")\n",
    "        wandb.define_metric(\"Train/*\", step_metric=\"Train/epoch\")\n",
    "        wandb.define_metric(\"Val/epoch\")\n",
    "        wandb.define_metric(\"Val/*\", step_metric=\"Val/epoch\")\n",
    "        n_train = train_set.__len__()\n",
    "        n_val = val_set.__len__()\n",
    "        n_test = test_set.__len__()\n",
    "        train(model, train_loader, val_loader, eval_time, num_epoch, n_train, n_val, temperature, lr, device)\n",
    "        test(model, test_loader, n_test, temperature, device)\n",
    "        run.finish()\n",
    "        del model\n",
    "        gc.collect()\n",
    "        \n",
    "  \n",
    "experiment_5_1() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760ebff3-004b-4210-b156-510e7acaf7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----channel_combinations =  ['BGR', 'GR', 'BG', 'R', 'G', 'B']----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "FLOPs: 29.921M\n",
      "Params: 26.014M\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:akvowbee) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train/acc</td><td>▁</td></tr><tr><td>Train/epoch</td><td>▁</td></tr><tr><td>Train/loss</td><td>▁</td></tr><tr><td>Val/acc</td><td>▁</td></tr><tr><td>Val/epoch</td><td>▁</td></tr><tr><td>Val/loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train/acc</td><td>0.03872</td></tr><tr><td>Train/epoch</td><td>0</td></tr><tr><td>Train/loss</td><td>0.03001</td></tr><tr><td>Val/acc</td><td>0.08</td></tr><tr><td>Val/epoch</td><td>0</td></tr><tr><td>Val/loss</td><td>0.03129</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">DynamicCNN_combination= BGR+GR+BG+R+G+B</strong> at: <a href='https://wandb.ai/sunny2021137/task1_experiment_2/runs/akvowbee' target=\"_blank\">https://wandb.ai/sunny2021137/task1_experiment_2/runs/akvowbee</a><br/> View project at: <a href='https://wandb.ai/sunny2021137/task1_experiment_2' target=\"_blank\">https://wandb.ai/sunny2021137/task1_experiment_2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240619_114105-akvowbee/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:akvowbee). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/p76121194/dl_hw2/wandb/run-20240619_114504-mzmvu1sr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sunny2021137/task1_experiment_2/runs/mzmvu1sr' target=\"_blank\">DynamicCNN_combination= BGR+GR+BG+R+G+B</a></strong> to <a href='https://wandb.ai/sunny2021137/task1_experiment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sunny2021137/task1_experiment_2' target=\"_blank\">https://wandb.ai/sunny2021137/task1_experiment_2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sunny2021137/task1_experiment_2/runs/mzmvu1sr' target=\"_blank\">https://wandb.ai/sunny2021137/task1_experiment_2/runs/mzmvu1sr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[001/040] 74.99 sec(s) Train Acc: 0.038721 Loss: 0.030010 | Val Acc: 0.080000 loss: 0.031293\n",
      "1\n",
      "[002/040] 76.47 sec(s) Train Acc: 0.105882 Loss: 0.026498 | Val Acc: 0.102222 loss: 0.028650\n",
      "2\n",
      "[003/040] 76.26 sec(s) Train Acc: 0.138081 Loss: 0.025206 | Val Acc: 0.151111 loss: 0.026838\n",
      "3\n",
      "[004/040] 75.86 sec(s) Train Acc: 0.164595 Loss: 0.024218 | Val Acc: 0.164444 loss: 0.025603\n",
      "4\n",
      "[005/040] 75.93 sec(s) Train Acc: 0.189814 Loss: 0.023214 | Val Acc: 0.206667 loss: 0.024524\n",
      "5\n",
      "[006/040] 76.13 sec(s) Train Acc: 0.212807 Loss: 0.022381 | Val Acc: 0.213333 loss: 0.023362\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# channel combination\n",
    "def experiment_3_1_2(nof_kernels):\n",
    "    # 超參數\n",
    "    #############\n",
    "    eval_time = 1\n",
    "    num_epoch = 40\n",
    "    num_classes = 50\n",
    "    img_size = 144\n",
    "    input_size = 128\n",
    "    batch_size = 128\n",
    "    lr = 0.001\n",
    "    temperature = 1\n",
    "    nof_kernels = nof_kernels\n",
    "    #############\n",
    "    set_seed(42)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    x, y = load_img('train.txt')\n",
    "    vx, vy = load_img('val.txt')\n",
    "    tx, ty = load_img('test.txt')\n",
    "    \n",
    "    # 產生隨機組合通道數的圖片\n",
    "    channel_combinations = [['BGR','GR','BG','R','G','B'], ['R','G','B'],['BG','GR'],['R', 'BG','BGR'], ['R', 'BG'], ['B', 'BG']]\n",
    "    \n",
    "    for combination in channel_combinations:\n",
    "        print(\"----channel_combinations = \", combination, end=\"----\\n\")\n",
    "        c, x_new = random_channel(x, combination)\n",
    "        vc, vx_new = random_channel(vx, combination)\n",
    "        tc, tx_new = random_channel(tx, combination)\n",
    "        \n",
    "       \n",
    "        # 填補成三通道\n",
    "        c, x_resize = resize_input(c, x_new, img_size=img_size)\n",
    "        vc, vx_resize = resize_input(vc, vx_new, img_size=img_size)\n",
    "        tc, tx_resize = resize_input(tc, tx_new, img_size=img_size)\n",
    "        del x_new, vx_new, tx_new\n",
    "        \n",
    "        # 定義transform\n",
    "        # training 時做 data augmentation\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((img_size, img_size)),  # 縮放\n",
    "            transforms.RandomRotation(degrees=30),  # 旋轉\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 平移\n",
    "            transforms.RandomCrop(input_size),  # 隨機裁剪\n",
    "            transforms.RandomHorizontalFlip(),  # 水平翻轉\n",
    "            transforms.ToTensor(),  # 轉換為Tensor\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 標準化\n",
    "\n",
    "        ])\n",
    "        # testing 時不需做 data augmentation\n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((img_size, img_size)),  # 縮放\n",
    "            transforms.CenterCrop(input_size),  # 中心裁剪\n",
    "            transforms.ToTensor(),  # 轉換為Tensor\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 標準化\n",
    "        ])\n",
    "        # data loader\n",
    "        train_set = ImgDataset(x_resize, y, train_transform)\n",
    "        val_set = ImgDataset(vx_resize, vy, test_transform)\n",
    "        test_set = ImgDataset(tx_resize, ty, test_transform)\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, worker_init_fn=lambda _: np.random.seed(42), num_workers=4)\n",
    "        val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "        test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "        del x_resize, vx_resize, tx_resize\n",
    "        \n",
    "        wandb.login()\n",
    "        \n",
    "        for model_name in ['DynamicCNN', 'base_model']:\n",
    "            # create model\n",
    "            model = create_model(model_name, nof_kernels=nof_kernels).to(device)\n",
    "            # 測FLOPs、params\n",
    "            # 创建输入张量\n",
    "            inputs = torch.randn(1, 3, input_size, input_size)\n",
    "            calc_complexity(model, inputs.to(device))\n",
    "            \n",
    "            run = wandb.init(\n",
    "            # Set the project where this run will be logged\n",
    "            project=\"task1_experiment_3_1_2\",\n",
    "            name=model_name+\"_combination= \"+\"+\".join(combination),\n",
    "            config={\n",
    "                \"model\": model_name,\n",
    "                \"learning_rate\": lr,\n",
    "                \"epochs\": num_epoch,\n",
    "                \"input_size\": input_size,\n",
    "                \"nof_kernels\": nof_kernels,\n",
    "                \"channel_combination\": \"+\".join(combination)\n",
    "            },)\n",
    "            wandb.define_metric(\"Train/epoch\")\n",
    "            wandb.define_metric(\"Train/*\", step_metric=\"Train/epoch\")\n",
    "            wandb.define_metric(\"Val/epoch\")\n",
    "            wandb.define_metric(\"Val/*\", step_metric=\"Val/epoch\")\n",
    "            n_train = train_set.__len__()\n",
    "            n_val = val_set.__len__()\n",
    "            n_test = test_set.__len__()\n",
    "            train(model, train_loader, val_loader, eval_time, num_epoch, n_train, n_val, temperature, lr, device)\n",
    "            test(model, test_loader, n_test, temperature, device)\n",
    "            run.finish()\n",
    "            del model\n",
    "            gc.collect()\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "experiment_3_1_2(nof_kernels=7)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d6b91a-f0e4-43c1-b641-a4a6e5f67d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----channel_combinations =  ['B']----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msunny2021137\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "FLOPs: 29.921M\n",
      "Params: 26.014M\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/p76121194/dl_hw2/wandb/run-20240620_093941-5ldspiyu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sunny2021137/task1_experiment_3/runs/5ldspiyu' target=\"_blank\">DynamicCNN_combination= B</a></strong> to <a href='https://wandb.ai/sunny2021137/task1_experiment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sunny2021137/task1_experiment_3' target=\"_blank\">https://wandb.ai/sunny2021137/task1_experiment_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sunny2021137/task1_experiment_3/runs/5ldspiyu' target=\"_blank\">https://wandb.ai/sunny2021137/task1_experiment_3/runs/5ldspiyu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[001/040] 61.39 sec(s) Train Acc: 0.102029 Loss: 0.027031 | Val Acc: 0.122222 loss: 0.029238\n",
      "1\n",
      "[002/040] 68.83 sec(s) Train Acc: 0.177702 Loss: 0.023546 | Val Acc: 0.144444 loss: 0.027431\n",
      "2\n",
      "[003/040] 71.42 sec(s) Train Acc: 0.225409 Loss: 0.021756 | Val Acc: 0.215556 loss: 0.024584\n",
      "3\n",
      "[004/040] 71.15 sec(s) Train Acc: 0.266861 Loss: 0.020341 | Val Acc: 0.277778 loss: 0.021021\n",
      "4\n",
      "[005/040] 72.08 sec(s) Train Acc: 0.298160 Loss: 0.019291 | Val Acc: 0.217778 loss: 0.026459\n",
      "5\n",
      "[006/040] 71.24 sec(s) Train Acc: 0.324485 Loss: 0.018391 | Val Acc: 0.226667 loss: 0.027529\n",
      "6\n",
      "[007/040] 71.23 sec(s) Train Acc: 0.347698 Loss: 0.017627 | Val Acc: 0.317778 loss: 0.021367\n",
      "7\n",
      "[008/040] 71.27 sec(s) Train Acc: 0.367769 Loss: 0.016901 | Val Acc: 0.320000 loss: 0.021035\n",
      "8\n",
      "[009/040] 71.38 sec(s) Train Acc: 0.387256 Loss: 0.016338 | Val Acc: 0.295556 loss: 0.021330\n",
      "9\n",
      "[010/040] 71.34 sec(s) Train Acc: 0.406932 Loss: 0.015748 | Val Acc: 0.380000 loss: 0.018899\n",
      "10\n",
      "[011/040] 71.01 sec(s) Train Acc: 0.422645 Loss: 0.015280 | Val Acc: 0.282222 loss: 0.022490\n",
      "11\n",
      "[012/040] 70.66 sec(s) Train Acc: 0.435610 Loss: 0.014793 | Val Acc: 0.417778 loss: 0.016360\n",
      "12\n",
      "[013/040] 70.65 sec(s) Train Acc: 0.455949 Loss: 0.014322 | Val Acc: 0.404444 loss: 0.017983\n",
      "13\n",
      "[014/040] 71.90 sec(s) Train Acc: 0.467430 Loss: 0.013911 | Val Acc: 0.497778 loss: 0.015207\n",
      "14\n",
      "[015/040] 71.47 sec(s) Train Acc: 0.481927 Loss: 0.013484 | Val Acc: 0.435556 loss: 0.015942\n",
      "15\n",
      "[016/040] 71.35 sec(s) Train Acc: 0.494781 Loss: 0.013110 | Val Acc: 0.342222 loss: 0.021198\n",
      "16\n",
      "[017/040] 71.11 sec(s) Train Acc: 0.506135 Loss: 0.012783 | Val Acc: 0.353333 loss: 0.020635\n",
      "17\n",
      "[018/040] 71.51 sec(s) Train Acc: 0.515815 Loss: 0.012448 | Val Acc: 0.415556 loss: 0.019136\n",
      "18\n",
      "[019/040] 72.44 sec(s) Train Acc: 0.527233 Loss: 0.012140 | Val Acc: 0.500000 loss: 0.015191\n",
      "19\n",
      "[020/040] 72.11 sec(s) Train Acc: 0.534939 Loss: 0.011925 | Val Acc: 0.375556 loss: 0.022259\n",
      "20\n",
      "[021/040] 71.53 sec(s) Train Acc: 0.546972 Loss: 0.011612 | Val Acc: 0.471111 loss: 0.015140\n",
      "21\n",
      "[022/040] 71.39 sec(s) Train Acc: 0.554062 Loss: 0.011372 | Val Acc: 0.464444 loss: 0.015907\n",
      "22\n",
      "[023/040] 71.16 sec(s) Train Acc: 0.564832 Loss: 0.011084 | Val Acc: 0.471111 loss: 0.016063\n",
      "23\n",
      "[024/040] 70.91 sec(s) Train Acc: 0.570312 Loss: 0.010857 | Val Acc: 0.431111 loss: 0.018151\n",
      "24\n",
      "[025/040] 70.87 sec(s) Train Acc: 0.579076 Loss: 0.010666 | Val Acc: 0.444444 loss: 0.016571\n",
      "25\n",
      "[026/040] 71.07 sec(s) Train Acc: 0.584145 Loss: 0.010479 | Val Acc: 0.435556 loss: 0.019132\n",
      "26\n",
      "[027/040] 71.42 sec(s) Train Acc: 0.593983 Loss: 0.010242 | Val Acc: 0.482222 loss: 0.015888\n",
      "27\n",
      "[028/040] 71.99 sec(s) Train Acc: 0.598958 Loss: 0.010072 | Val Acc: 0.475556 loss: 0.016583\n",
      "28\n",
      "[029/040] 71.45 sec(s) Train Acc: 0.605559 Loss: 0.009901 | Val Acc: 0.455556 loss: 0.016018\n",
      "29\n",
      "[030/040] 71.06 sec(s) Train Acc: 0.611875 Loss: 0.009759 | Val Acc: 0.482222 loss: 0.015714\n",
      "30\n",
      "[031/040] 71.28 sec(s) Train Acc: 0.617023 Loss: 0.009535 | Val Acc: 0.468889 loss: 0.016332\n",
      "31\n",
      "[032/040] 71.46 sec(s) Train Acc: 0.623466 Loss: 0.009405 | Val Acc: 0.551111 loss: 0.013988\n",
      "32\n",
      "[033/040] 71.37 sec(s) Train Acc: 0.632594 Loss: 0.009221 | Val Acc: 0.440000 loss: 0.018140\n",
      "33\n",
      "[034/040] 70.98 sec(s) Train Acc: 0.634015 Loss: 0.009090 | Val Acc: 0.406667 loss: 0.021361\n",
      "34\n",
      "[035/040] 71.08 sec(s) Train Acc: 0.638184 Loss: 0.008935 | Val Acc: 0.373333 loss: 0.021567\n",
      "35\n",
      "[036/040] 71.12 sec(s) Train Acc: 0.645322 Loss: 0.008793 | Val Acc: 0.540000 loss: 0.014687\n",
      "36\n",
      "[037/040] 70.94 sec(s) Train Acc: 0.651891 Loss: 0.008677 | Val Acc: 0.500000 loss: 0.014818\n",
      "37\n",
      "[038/040] 70.93 sec(s) Train Acc: 0.655413 Loss: 0.008503 | Val Acc: 0.444444 loss: 0.020370\n",
      "38\n",
      "[039/040] 71.16 sec(s) Train Acc: 0.659834 Loss: 0.008377 | Val Acc: 0.553333 loss: 0.013525\n",
      "39\n",
      "[040/040] 71.49 sec(s) Train Acc: 0.663845 Loss: 0.008286 | Val Acc: 0.544444 loss: 0.014063\n",
      "--------Test result-------------\n",
      "Accuracy: 0.5422\n",
      "Precision: 0.5738\n",
      "Recall: 0.5422\n",
      "F1-score: 0.5379\n",
      "Loss: 0.0000\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test/Accuracy</td><td>▁</td></tr><tr><td>Test/F1-score</td><td>▁</td></tr><tr><td>Test/Loss</td><td>▁</td></tr><tr><td>Test/Precision</td><td>▁</td></tr><tr><td>Test/Recall</td><td>▁</td></tr><tr><td>Train/acc</td><td>▁▂▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>Train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>Train/loss</td><td>█▇▆▆▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val/acc</td><td>▁▁▃▄▃▃▄▄▄▅▄▆▆▇▆▅▅▆▇▅▇▇▇▆▆▆▇▇▆▇▇█▆▆▅█▇▆██</td></tr><tr><td>Val/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>Val/loss</td><td>█▇▆▄▇▇▄▄▄▃▅▂▃▂▂▄▄▃▂▅▂▂▂▃▂▃▂▂▂▂▂▁▃▄▅▂▂▄▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test/Accuracy</td><td>0.54222</td></tr><tr><td>Test/F1-score</td><td>0.53794</td></tr><tr><td>Test/Loss</td><td>0.01383</td></tr><tr><td>Test/Precision</td><td>0.57383</td></tr><tr><td>Test/Recall</td><td>0.54222</td></tr><tr><td>Train/acc</td><td>0.66385</td></tr><tr><td>Train/epoch</td><td>39</td></tr><tr><td>Train/loss</td><td>0.00829</td></tr><tr><td>Val/acc</td><td>0.54444</td></tr><tr><td>Val/epoch</td><td>39</td></tr><tr><td>Val/loss</td><td>0.01406</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">DynamicCNN_combination= B</strong> at: <a href='https://wandb.ai/sunny2021137/task1_experiment_3/runs/5ldspiyu' target=\"_blank\">https://wandb.ai/sunny2021137/task1_experiment_3/runs/5ldspiyu</a><br/> View project at: <a href='https://wandb.ai/sunny2021137/task1_experiment_3' target=\"_blank\">https://wandb.ai/sunny2021137/task1_experiment_3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240620_093941-5ldspiyu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "FLOPs: 261.907M\n",
      "Params: 17.718M\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/p76121194/dl_hw2/wandb/run-20240620_102717-qfdcxgf5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sunny2021137/task1_experiment_3/runs/qfdcxgf5' target=\"_blank\">base_model_combination= B</a></strong> to <a href='https://wandb.ai/sunny2021137/task1_experiment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sunny2021137/task1_experiment_3' target=\"_blank\">https://wandb.ai/sunny2021137/task1_experiment_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sunny2021137/task1_experiment_3/runs/qfdcxgf5' target=\"_blank\">https://wandb.ai/sunny2021137/task1_experiment_3/runs/qfdcxgf5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[001/040] 45.29 sec(s) Train Acc: 0.101603 Loss: 0.027028 | Val Acc: 0.126667 loss: 0.028076\n",
      "1\n",
      "[002/040] 45.02 sec(s) Train Acc: 0.170138 Loss: 0.023949 | Val Acc: 0.144444 loss: 0.028624\n",
      "2\n",
      "[003/040] 45.01 sec(s) Train Acc: 0.214291 Loss: 0.022372 | Val Acc: 0.186667 loss: 0.024632\n",
      "3\n",
      "[004/040] 44.72 sec(s) Train Acc: 0.247896 Loss: 0.021072 | Val Acc: 0.213333 loss: 0.025085\n",
      "4\n",
      "[005/040] 44.81 sec(s) Train Acc: 0.277158 Loss: 0.020067 | Val Acc: 0.153333 loss: 0.031732\n",
      "5\n",
      "[006/040] 44.88 sec(s) Train Acc: 0.304098 Loss: 0.019113 | Val Acc: 0.284444 loss: 0.022064\n",
      "6\n",
      "[007/040] 44.80 sec(s) Train Acc: 0.323916 Loss: 0.018396 | Val Acc: 0.308889 loss: 0.020868\n",
      "7\n",
      "[008/040] 44.46 sec(s) Train Acc: 0.346372 Loss: 0.017718 | Val Acc: 0.368889 loss: 0.018468\n",
      "8\n",
      "[009/040] 44.62 sec(s) Train Acc: 0.364185 Loss: 0.017106 | Val Acc: 0.251111 loss: 0.025577\n",
      "9\n",
      "[010/040] 44.66 sec(s) Train Acc: 0.380876 Loss: 0.016553 | Val Acc: 0.328889 loss: 0.020263\n",
      "10\n",
      "[011/040] 44.72 sec(s) Train Acc: 0.395878 Loss: 0.016114 | Val Acc: 0.340000 loss: 0.019841\n",
      "11\n",
      "[012/040] 44.71 sec(s) Train Acc: 0.412412 Loss: 0.015636 | Val Acc: 0.335556 loss: 0.020519\n",
      "12\n",
      "[013/040] 44.54 sec(s) Train Acc: 0.426625 Loss: 0.015193 | Val Acc: 0.422222 loss: 0.017390\n",
      "13\n",
      "[014/040] 44.85 sec(s) Train Acc: 0.435152 Loss: 0.014836 | Val Acc: 0.384444 loss: 0.018190\n",
      "14\n",
      "[015/040] 44.49 sec(s) Train Acc: 0.448006 Loss: 0.014452 | Val Acc: 0.386667 loss: 0.017959\n",
      "15\n",
      "[016/040] 44.19 sec(s) Train Acc: 0.462503 Loss: 0.014082 | Val Acc: 0.357778 loss: 0.019955\n",
      "16\n",
      "[017/040] 44.67 sec(s) Train Acc: 0.472325 Loss: 0.013727 | Val Acc: 0.453333 loss: 0.016442\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "# channel combination\n",
    "def experiment_3_1_1(nof_kernels):\n",
    "    # 超參數\n",
    "    #############\n",
    "    eval_time = 1\n",
    "    num_epoch = 40\n",
    "    num_classes = 50\n",
    "    img_size = 144\n",
    "    input_size = 128\n",
    "    batch_size = 128\n",
    "    lr = 0.001\n",
    "    temperature = 1\n",
    "    nof_kernels = nof_kernels\n",
    "    #############\n",
    "    set_seed(42)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    x, y = load_img('train.txt')\n",
    "    vx, vy = load_img('val.txt')\n",
    "    tx, ty = load_img('test.txt')\n",
    "    \n",
    "    # 產生隨機組合通道數的圖片\n",
    "    channel_combinations = [['B'], ['G'], ['R'], ['BG'], ['GR'], ['BGR']]\n",
    "    \n",
    "    for combination in channel_combinations:\n",
    "        print(\"----channel_combinations = \", combination, end=\"----\\n\")\n",
    "        c, x_new = random_channel(x, combination)\n",
    "        vc, vx_new = random_channel(vx, combination)\n",
    "        tc, tx_new = random_channel(tx, combination)\n",
    "        \n",
    "       \n",
    "        # 填補成三通道\n",
    "        c, x_resize = resize_input(c, x_new, img_size=img_size)\n",
    "        vc, vx_resize = resize_input(vc, vx_new, img_size=img_size)\n",
    "        tc, tx_resize = resize_input(tc, tx_new, img_size=img_size)\n",
    "        del x_new, vx_new, tx_new\n",
    "        \n",
    "        # 定義transform\n",
    "        # training 時做 data augmentation\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((img_size, img_size)),  # 縮放\n",
    "            transforms.RandomRotation(degrees=30),  # 旋轉\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 平移\n",
    "            transforms.RandomCrop(input_size),  # 隨機裁剪\n",
    "            transforms.RandomHorizontalFlip(),  # 水平翻轉\n",
    "            transforms.ToTensor(),  # 轉換為Tensor\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 標準化\n",
    "\n",
    "        ])\n",
    "        # testing 時不需做 data augmentation\n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((img_size, img_size)),  # 縮放\n",
    "            transforms.CenterCrop(input_size),  # 中心裁剪\n",
    "            transforms.ToTensor(),  # 轉換為Tensor\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 標準化\n",
    "        ])\n",
    "        # data loader\n",
    "        train_set = ImgDataset(x_resize, y, train_transform)\n",
    "        val_set = ImgDataset(vx_resize, vy, test_transform)\n",
    "        test_set = ImgDataset(tx_resize, ty, test_transform)\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, worker_init_fn=lambda _: np.random.seed(42), num_workers=4)\n",
    "        val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "        test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "        del x_resize, vx_resize, tx_resize\n",
    "        \n",
    "        wandb.login()\n",
    "        \n",
    "        for model_name in ['DynamicCNN', 'base_model']:\n",
    "            # create model\n",
    "            model = create_model(model_name, nof_kernels=nof_kernels).to(device)\n",
    "            # 測FLOPs、params\n",
    "            # 创建输入张量\n",
    "            inputs = torch.randn(1, 3, input_size, input_size)\n",
    "            calc_complexity(model, inputs.to(device))\n",
    "            \n",
    "            run = wandb.init(\n",
    "            # Set the project where this run will be logged\n",
    "            project=\"task1_experiment_3_1_1\",\n",
    "            name=model_name+\"_combination= \"+\"+\".join(combination),\n",
    "            config={\n",
    "                \"model\": model_name,\n",
    "                \"learning_rate\": lr,\n",
    "                \"epochs\": num_epoch,\n",
    "                \"input_size\": input_size,\n",
    "                \"nof_kernels\": nof_kernels,\n",
    "                \"channel_combination\": \"+\".join(combination)\n",
    "            },)\n",
    "            wandb.define_metric(\"Train/epoch\")\n",
    "            wandb.define_metric(\"Train/*\", step_metric=\"Train/epoch\")\n",
    "            wandb.define_metric(\"Val/epoch\")\n",
    "            wandb.define_metric(\"Val/*\", step_metric=\"Val/epoch\")\n",
    "            n_train = train_set.__len__()\n",
    "            n_val = val_set.__len__()\n",
    "            n_test = test_set.__len__()\n",
    "            train(model, train_loader, val_loader, eval_time, num_epoch, n_train, n_val, temperature, lr, device)\n",
    "            test(model, test_loader, n_test, temperature, device)\n",
    "            run.finish()\n",
    "            del model\n",
    "            gc.collect()\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "experiment_3_1_1(nof_kernels=7)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efc4356-5a55-4203-8cf7-3d98d78cb264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f852fa8f-5fa2-4856-a2d2-3b169ed78e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dl_hw1",
   "language": "python",
   "name": "dl_hw1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
