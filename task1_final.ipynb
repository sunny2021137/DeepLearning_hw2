{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b00d1bd1-e2e0-4f71-a873-abe8c8b03b1f",
   "metadata": {
    "id": "b00d1bd1-e2e0-4f71-a873-abe8c8b03b1f"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn import init\n",
    "from torch.nn.modules.utils import _pair\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from thop import profile, clever_format\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67dd633a-ba38-4d5b-919f-a9d740b05f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cafd4235-5d5c-4d34-be4d-aed1d42d25f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, c_dim, hidden_dim, nof_kernels, out_channel, in_channel):\n",
    "        super().__init__()\n",
    "        self.nof_kernels = nof_kernels\n",
    "        self.out_channel = out_channel\n",
    "        self.in_channel = in_channel\n",
    "        self.global_pooling = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Flatten())\n",
    "        self.to_scores = nn.Sequential(nn.Linear(in_channel, hidden_dim),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       nn.Linear(hidden_dim, nof_kernels*out_channel*in_channel)\n",
    "                                      )\n",
    "\n",
    "    def forward(self, x, temperature=1):\n",
    "        out = self.global_pooling(x)\n",
    "        scores = self.to_scores(out)\n",
    "        scores = scores.reshape(x.shape[0], self.nof_kernels, self.out_channel, self.in_channel)\n",
    "        return F.softmax(scores / temperature, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b03bd3a5-273e-48d7-bc94-0e1ae51cc232",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicConv2d(nn.Module):\n",
    "    def __init__(self, nof_kernels, reduce, in_channels, out_channels, kernel_size,\n",
    "                 stride=1, padding=0, dilation=1, bias=True):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.conv_args = {'stride': stride, 'padding': padding, 'dilation': dilation}\n",
    "        self.nof_kernels = nof_kernels\n",
    "        self.kernel_size = _pair(kernel_size)\n",
    "        # kernels_weights: (nof_kernels, out_channels, in_channels, *self.kernel_size)\n",
    "        self.kernels_weights = nn.Parameter(torch.Tensor(\n",
    "            nof_kernels, out_channels, in_channels, *self.kernel_size), requires_grad=True)\n",
    "        if bias:\n",
    "            self.kernels_bias = nn.Parameter(torch.Tensor(out_channels), requires_grad=True)\n",
    "        else:\n",
    "            self.register_parameter('kernels_bias', None)\n",
    "\n",
    "        self.attention = AttentionLayer(3, max(8, in_channels // reduce), nof_kernels, out_channels, in_channels)\n",
    "        self.initialize_parameters()\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        for i_kernel in range(self.nof_kernels):\n",
    "            init.kaiming_uniform_(self.kernels_weights[i_kernel], a=math.sqrt(5))\n",
    "        if self.kernels_bias is not None:\n",
    "            bound = 1 / math.sqrt(self.kernels_weights[0, 0].numel())\n",
    "            nn.init.uniform_(self.kernels_bias, -bound, bound)\n",
    "\n",
    "    def forward(self, x, temperature=1):\n",
    "        # x: (batch_size , in_channels , H , W)\n",
    "        batch_size = x.shape[0]\n",
    "        # alphas: (batch_size , nof_kernels, self.out_channels, self.in_channels)\n",
    "        alphas = self.attention(x, temperature)\n",
    "\n",
    "        # self.kernels_weights.unsqueeze(0): (1, nof_kernels, out_channels, in_channels, self.kernel_size, self.kernel_size)\n",
    "        # alphas.view(): (batch_size , nof_kernels, self.out_channels, self.in_channels, 1, 1)\n",
    "        # agg_weights: (batch_size, self.out_channels, self.in_channels, self.kernel_size, self.kernel_size)\n",
    "        agg_weights = torch.sum(\n",
    "            torch.mul(self.kernels_weights.unsqueeze(0), alphas.view(batch_size, self.nof_kernels, self.out_channels, self.in_channels, 1, 1)), dim=1)\n",
    "\n",
    "        # agg_weights: (batch_size * out_channels , in_channels, kernel_size, kernel_size)\n",
    "        agg_weights = agg_weights.view(-1, *agg_weights.shape[-3:])\n",
    "\n",
    "\n",
    "        if self.kernels_bias is not None:\n",
    "            agg_bias = self.kernels_bias.repeat(batch_size)\n",
    "        else:\n",
    "            agg_bias = None\n",
    "\n",
    "        x_grouped = x.view(1, -1, *x.shape[-2:])  # (1 , batch_size*out_c , H , W)\n",
    "        #   out: (1 , batch_size*out_C , H' , W')\n",
    "        out = F.conv2d(x_grouped, agg_weights, agg_bias, groups=batch_size,\n",
    "                        **self.conv_args)\n",
    "        # out: (batch_size , out_channels , H' , W')\n",
    "        out = out.view(batch_size, -1, *out.shape[-2:])\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a331090-a425-40af-848c-51af5a7d6637",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicCNN(nn.Module):\n",
    "    def __init__(self, num_classes=50, nof_kernels=4):\n",
    "        super(DynamicCNN, self).__init__()\n",
    "        self.dycnn = nn.ModuleList([\n",
    "            DynamicConv2d(nof_kernels=nof_kernels, reduce=4, in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1, dilation=1, bias=True),\n",
    "                    DynamicConv2d(nof_kernels=nof_kernels, reduce=4, in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1, dilation=1, bias=True),\n",
    "                      DynamicConv2d(nof_kernels=nof_kernels, reduce=4, in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, dilation=1, bias=True),\n",
    "                      DynamicConv2d(nof_kernels=nof_kernels, reduce=4, in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, dilation=1, bias=True)\n",
    "                     ])\n",
    "        self.norm =  nn.ModuleList([nn.BatchNorm2d((2**i) * 32) for i in range(4)])\n",
    "        self.act = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2, 0)\n",
    "\n",
    "            \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*8*8, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, temperature=1):\n",
    "        out = x\n",
    "        for i in range(4):\n",
    "            out = self.dycnn[i](out, temperature=temperature)\n",
    "            out = self.norm[i](out)\n",
    "            out = self.act(out)\n",
    "            out = self.pool(out)\n",
    "            \n",
    "        out = out.view(out.size()[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "079064bd-bea3-4ce6-ba89-0014fad6fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=50):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, 1, 1), # [32, 128, 128]\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [32, 64, 64]\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, 1, 1), # [64, 64, 64]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [64, 32, 32]\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, 1), # [128, 32, 32]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [128, 16, 16]\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, 1, 1), # [256, 16, 16]\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),       # [256, 8, 8]\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*8*8, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, temperature=1):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aca5383e-bdc2-4111-bdb1-1559a45bb702",
   "metadata": {
    "id": "aca5383e-bdc2-4111-bdb1-1559a45bb702"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, x, y=None, transform=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        if y is not None:\n",
    "            self.y = torch.LongTensor(y)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, index):\n",
    "        X = self.x[index]\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        if self.y is not None:\n",
    "            Y = self.y[index]\n",
    "            return X, Y\n",
    "        else:\n",
    "            return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c4b9ecf-81b1-497d-83a9-fcb1b58d03d0",
   "metadata": {
    "id": "6c4b9ecf-81b1-497d-83a9-fcb1b58d03d0"
   },
   "outputs": [],
   "source": [
    "def random_channel(images, channel_combinations):\n",
    "    channel_dict = {i:c for i,c in enumerate(channel_combinations)}\n",
    "    new_images = []\n",
    "    n = len(list(channel_dict.keys()))\n",
    "    channels = []\n",
    "    for i, image in enumerate(images):\n",
    "        channel_idx = i % n\n",
    "        # 修改通道\n",
    "        if channel_dict[channel_idx] == 'BGR':\n",
    "            img = image[:, :, :]\n",
    "        elif channel_dict[channel_idx] == 'GR':\n",
    "            img = image[:, :, 1:]\n",
    "        elif channel_dict[channel_idx] == 'BG':\n",
    "            img = image[:, :, :2]\n",
    "        elif channel_dict[channel_idx] == 'R':\n",
    "            img = image[:, :, 2:3]\n",
    "        elif channel_dict[channel_idx] == 'G':\n",
    "            img = image[:, :, 1:2]\n",
    "        elif channel_dict[channel_idx] == 'B':\n",
    "            img = image[:, :, 0:1]\n",
    "        else:\n",
    "            print(\"error\")\n",
    "        new_images.append(img)\n",
    "        channels.append(channel_dict[channel_idx])\n",
    "    return channels, new_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f28a9c5-be30-441e-abe6-8d5bf30c1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name, nof_kernels=4):\n",
    "    model = None\n",
    "    if model_name == \"DynamicCNN\":\n",
    "        model = DynamicCNN(num_classes=50, nof_kernels=nof_kernels)\n",
    "    elif model_name == \"base_model\":\n",
    "        model = SimpleCNN(num_classes=50)\n",
    "        \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "274ca17c-2a38-4461-b261-cdcb8c1d161e",
   "metadata": {
    "id": "274ca17c-2a38-4461-b261-cdcb8c1d161e"
   },
   "outputs": [],
   "source": [
    "def load_img(f):\n",
    "    shapes = []\n",
    "    f=open(f)\n",
    "    lines=f.readlines()\n",
    "    imgs, lab=[], []\n",
    "    for i in range(len(lines)):\n",
    "        fn, label = lines[i].split(' ')\n",
    "        im1=cv2.imread(fn)\n",
    "\n",
    "        if im1.shape[2] not in shapes:\n",
    "            shapes.append(im1.shape[2])\n",
    "\n",
    "        imgs.append(im1)\n",
    "        lab.append(int(label))\n",
    "\n",
    "    \n",
    "    lab= np.asarray(lab, np.uint8)\n",
    "    \n",
    "    return imgs, lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b56c455f-a089-46f5-ae1b-86b24d72adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_input(channels, images, img_size):\n",
    "    channel_map = {\"BGR\": torch.tensor([1,1,1]), \"BG\":torch.tensor([1,1,0]), \"GR\":torch.tensor([0,1,1]), \"B\":torch.tensor([1,0,0]), \"G\":torch.tensor([0,1,0]), \"R\":torch.tensor([0,0,1])}\n",
    "    x = np.zeros((len(images), img_size, img_size, 3), dtype=np.uint8)\n",
    "    c = np.zeros((len(images), 3),  dtype=np.uint8)\n",
    "    for i, img in enumerate(images):\n",
    "        # 3通道圖片\n",
    "        img_3channel = np.zeros((img_size, img_size, 3), dtype=img.dtype)\n",
    "        \n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "\n",
    "        if channels[i] == \"B\":\n",
    "            img_3channel[:, :, 0] = img \n",
    "        elif channels[i] == \"G\":\n",
    "            img_3channel[:, :, 1] = img \n",
    "        elif channels[i] == \"R\":\n",
    "            img_3channel[:, :, 2] = img \n",
    "        elif channels[i] == \"BGR\":\n",
    "            img_3channel = img\n",
    "        elif channels[i] == \"BG\":\n",
    "            # 合併成三通道圖像\n",
    "            img_3channel[:, :, :2] = img  # 前兩個通道保持不變\n",
    "        elif channels[i] == \"GR\":\n",
    "            img_3channel[:, :, 1:] = img  # 後兩個通道保持不變\n",
    "        else:\n",
    "            print(\"error\")\n",
    "        x[i, :, :, :] = img_3channel\n",
    "        c[i, :] = channel_map[channels[i]]\n",
    "    return c, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4948f163-08bc-48d3-8d20-449b23071e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_complexity(model, inputs):\n",
    "    # 计算FLOPs和参数量\n",
    "    flops, params = profile(model, inputs=(inputs,))\n",
    "    flops, params = clever_format([flops, params], \"%.3f\")\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "879b291b-2ea9-4182-9366-0b15c78819d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, eval_time, num_epoch, n_train, n_val, temperature, lr, device):\n",
    "    # print(\"--4--\")\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # model = model.to(device)\n",
    "\n",
    "    loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr) # optimizer 使用 Adam\n",
    "\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        print(epoch)\n",
    "        \n",
    "        epoch_start_time = time.time()\n",
    "        train_acc = 0.0\n",
    "        train_loss = 0.0\n",
    "        val_acc = 0.0\n",
    "        val_loss = 0.0\n",
    "\n",
    "        model.train() # 確保 model 是在 train model (開啟 Dropout 等...)\n",
    "        for i, data in enumerate(train_loader):\n",
    "            optimizer.zero_grad() # 用 optimizer 將 model 參數的 gradient 歸零\n",
    "            \n",
    "            train_pred = model(data[0].to(device), temperature=temperature) # 利用 model 得到預測的機率分佈 這邊實際上就是去呼叫 model 的 forward 函數\n",
    "            batch_loss = loss(train_pred, data[1].to(device)) # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\n",
    "            batch_loss.backward() # 利用 back propagation 算出每個參數的 gradient\n",
    "            optimizer.step() # 以 optimizer 用 gradient 更新參數值\n",
    "\n",
    "            train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "            train_loss += batch_loss.item()\n",
    "\n",
    "        if epoch % eval_time == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(val_loader):\n",
    "                    val_pred = model(data[0].to(device), temperature=temperature)\n",
    "                    batch_loss = loss(val_pred, data[1].to(device))\n",
    "\n",
    "                    val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "                    val_loss += batch_loss.item()\n",
    "\n",
    "                # 將結果 print 出來\n",
    "                print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n",
    "                    (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n",
    "                     train_acc/n_train, train_loss/n_train, val_acc/n_val, val_loss/n_val))\n",
    "\n",
    "                print(\"Train/epoch\",  epoch)\n",
    "                print(\"Train/acc\", train_acc/n_train)\n",
    "                print(\"Train/loss\", train_loss/n_train)\n",
    "                print(\"Val/epoch\", epoch)\n",
    "                print(\"Val/acc\", val_acc/n_val)\n",
    "                print(\"Val/loss\", val_loss/n_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "398843e5-8cdb-44e7-8c10-91147241758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, n_test, temperature, device):\n",
    "    model.eval()\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # model = model.to(device)\n",
    "    loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\n",
    "    \n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    test_acc = 0.0\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            test_pred = model(data[0].to(device), temperature=temperature)\n",
    "            batch_loss = loss(test_pred, data[1].to(device))\n",
    "            test_loss += batch_loss.item()\n",
    "\n",
    "            _, preds = torch.max(test_pred, 1)\n",
    "            all_labels.extend(data[1].cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "        recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "        print(\"--------Test result-------------\")\n",
    "        print(f'Accuracy: {accuracy:.4f}')\n",
    "        print(f'Precision: {precision:.4f}')\n",
    "        print(f'Recall: {recall:.4f}')\n",
    "        print(f'F1-score: {f1:.4f}')\n",
    "        print(f'Loss: {test_loss//n_test:.4f}')\n",
    "        print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712eff19-db2a-4a10-8906-548ec2d6242d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6662e4f1-ed9e-45ce-bdb0-ae66f253f698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nof_kernel\n",
    "def experiment_5_1():\n",
    "    # 超參數\n",
    "    #############\n",
    "    eval_time = 1\n",
    "    num_epoch = 50\n",
    "    num_classes = 30\n",
    "    img_size = 144\n",
    "    input_size = 128\n",
    "    batch_size = 128\n",
    "    lr = 0.001\n",
    "    model_name= 'DynamicCNN'\n",
    "    temperature = 1\n",
    "    #############\n",
    "    set_seed(42)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    x, y = load_img('train.txt')\n",
    "    vx, vy = load_img('val.txt')\n",
    "    tx, ty = load_img('test.txt')\n",
    "    print(\"--1--\")\n",
    "    # 產生隨機組合通道數的圖片\n",
    "    channel_combinations = ['BGR','GR','BG','R','G','B']\n",
    "    c, x_new = random_channel(x, channel_combinations)\n",
    "    vc, vx_new = random_channel(vx, channel_combinations)\n",
    "    tc, tx_new = random_channel(tx, channel_combinations)\n",
    "    del x, vx, tx\n",
    "    print(\"--2--\")\n",
    "    # 填補成三通道\n",
    "    c, x_resize = resize_input(c, x_new, img_size=img_size)\n",
    "    vc, vx_resize = resize_input(vc, vx_new, img_size=img_size)\n",
    "    tc, tx_resize = resize_input(tc, tx_new, img_size=img_size)\n",
    "    del x_new, vx_new, tx_new\n",
    "    print(\"--3--\")\n",
    "    # 定義transform\n",
    "    # training 時做 data augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((img_size, img_size)),  # 縮放\n",
    "        transforms.RandomRotation(degrees=30),  # 旋轉\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 平移\n",
    "        transforms.RandomCrop(input_size),  # 隨機裁剪\n",
    "        transforms.RandomHorizontalFlip(),  # 水平翻轉\n",
    "        transforms.ToTensor(),  # 轉換為Tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 標準化\n",
    "\n",
    "    ])\n",
    "    # testing 時不需做 data augmentation\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((img_size, img_size)),  # 縮放\n",
    "        transforms.CenterCrop(input_size),  # 中心裁剪\n",
    "        transforms.ToTensor(),  # 轉換為Tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 標準化\n",
    "    ])\n",
    "    # data loader\n",
    "    train_set = ImgDataset(x_resize, y, train_transform)\n",
    "    val_set = ImgDataset(vx_resize, vy, test_transform)\n",
    "    test_set = ImgDataset(tx_resize, ty, test_transform)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, worker_init_fn=lambda _: np.random.seed(42), num_workers=4)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    del x_resize, vx_resize, tx_resize\n",
    "    \n",
    "    print(\"--4--\")\n",
    "    for nof_kernels in [1, 3, 5, 7]:\n",
    "        print(\"-----number of kernels = \"+str(nof_kernels)+\"-----\")\n",
    "        # create model\n",
    "        model = create_model(model_name, nof_kernels=nof_kernels).to(device)\n",
    "        # 測FLOPs、params\n",
    "        # 创建输入张量\n",
    "        inputs = torch.randn(1, 3, input_size, input_size)\n",
    "        calc_complexity(model, inputs.to(device))\n",
    "        \n",
    "        \n",
    "        n_train = train_set.__len__()\n",
    "        n_val = val_set.__len__()\n",
    "        n_test = test_set.__len__()\n",
    "        train(model, train_loader, val_loader, eval_time, num_epoch, n_train, n_val, temperature, lr, device)\n",
    "        test(model, test_loader, n_test, temperature, device)\n",
    "        \n",
    "        del model\n",
    "        gc.collect()\n",
    "        \n",
    "  \n",
    "experiment_5_1() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760ebff3-004b-4210-b156-510e7acaf7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel combination\n",
    "def experiment_3_1_2(nof_kernels):\n",
    "    # 超參數\n",
    "    #############\n",
    "    eval_time = 1\n",
    "    num_epoch = 40\n",
    "    num_classes = 50\n",
    "    img_size = 144\n",
    "    input_size = 128\n",
    "    batch_size = 128\n",
    "    lr = 0.001\n",
    "    temperature = 1\n",
    "    nof_kernels = nof_kernels\n",
    "    #############\n",
    "    set_seed(42)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    x, y = load_img('train.txt')\n",
    "    vx, vy = load_img('val.txt')\n",
    "    tx, ty = load_img('test.txt')\n",
    "    \n",
    "    # 產生隨機組合通道數的圖片\n",
    "    channel_combinations = [['BGR','GR','BG','R','G','B'], ['R','G','B'],['BG','GR'],['R', 'BG','BGR'], ['R', 'BG'], ['B', 'BG']]\n",
    "    \n",
    "    for combination in channel_combinations:\n",
    "        print(\"----channel_combinations = \", combination, end=\"----\\n\")\n",
    "        c, x_new = random_channel(x, combination)\n",
    "        vc, vx_new = random_channel(vx, combination)\n",
    "        tc, tx_new = random_channel(tx, combination)\n",
    "        \n",
    "       \n",
    "        # 填補成三通道\n",
    "        c, x_resize = resize_input(c, x_new, img_size=img_size)\n",
    "        vc, vx_resize = resize_input(vc, vx_new, img_size=img_size)\n",
    "        tc, tx_resize = resize_input(tc, tx_new, img_size=img_size)\n",
    "        del x_new, vx_new, tx_new\n",
    "        \n",
    "        # 定義transform\n",
    "        # training 時做 data augmentation\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((img_size, img_size)),  # 縮放\n",
    "            transforms.RandomRotation(degrees=30),  # 旋轉\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 平移\n",
    "            transforms.RandomCrop(input_size),  # 隨機裁剪\n",
    "            transforms.RandomHorizontalFlip(),  # 水平翻轉\n",
    "            transforms.ToTensor(),  # 轉換為Tensor\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 標準化\n",
    "\n",
    "        ])\n",
    "        # testing 時不需做 data augmentation\n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((img_size, img_size)),  # 縮放\n",
    "            transforms.CenterCrop(input_size),  # 中心裁剪\n",
    "            transforms.ToTensor(),  # 轉換為Tensor\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 標準化\n",
    "        ])\n",
    "        # data loader\n",
    "        train_set = ImgDataset(x_resize, y, train_transform)\n",
    "        val_set = ImgDataset(vx_resize, vy, test_transform)\n",
    "        test_set = ImgDataset(tx_resize, ty, test_transform)\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, worker_init_fn=lambda _: np.random.seed(42), num_workers=4)\n",
    "        val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "        test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "        del x_resize, vx_resize, tx_resize\n",
    "        \n",
    "        \n",
    "        \n",
    "        for model_name in ['DynamicCNN', 'base_model']:\n",
    "            # create model\n",
    "            model = create_model(model_name, nof_kernels=nof_kernels).to(device)\n",
    "            # 測FLOPs、params\n",
    "            # 创建输入张量\n",
    "            inputs = torch.randn(1, 3, input_size, input_size)\n",
    "            calc_complexity(model, inputs.to(device))\n",
    "            \n",
    "            \n",
    "            n_train = train_set.__len__()\n",
    "            n_val = val_set.__len__()\n",
    "            n_test = test_set.__len__()\n",
    "            train(model, train_loader, val_loader, eval_time, num_epoch, n_train, n_val, temperature, lr, device)\n",
    "            test(model, test_loader, n_test, temperature, device)\n",
    "            \n",
    "            del model\n",
    "            gc.collect()\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "experiment_3_1_2(nof_kernels=7)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d6b91a-f0e4-43c1-b641-a4a6e5f67d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel combination\n",
    "def experiment_3_1_1(nof_kernels):\n",
    "    # 超參數\n",
    "    #############\n",
    "    eval_time = 1\n",
    "    num_epoch = 40\n",
    "    num_classes = 50\n",
    "    img_size = 144\n",
    "    input_size = 128\n",
    "    batch_size = 128\n",
    "    lr = 0.001\n",
    "    temperature = 1\n",
    "    nof_kernels = nof_kernels\n",
    "    #############\n",
    "    set_seed(42)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    x, y = load_img('train.txt')\n",
    "    vx, vy = load_img('val.txt')\n",
    "    tx, ty = load_img('test.txt')\n",
    "    \n",
    "    # 產生隨機組合通道數的圖片\n",
    "    channel_combinations = [['B'], ['G'], ['R'], ['BG'], ['GR'], ['BGR']]\n",
    "    \n",
    "    for combination in channel_combinations:\n",
    "        print(\"----channel_combinations = \", combination, end=\"----\\n\")\n",
    "        c, x_new = random_channel(x, combination)\n",
    "        vc, vx_new = random_channel(vx, combination)\n",
    "        tc, tx_new = random_channel(tx, combination)\n",
    "        \n",
    "       \n",
    "        # 填補成三通道\n",
    "        c, x_resize = resize_input(c, x_new, img_size=img_size)\n",
    "        vc, vx_resize = resize_input(vc, vx_new, img_size=img_size)\n",
    "        tc, tx_resize = resize_input(tc, tx_new, img_size=img_size)\n",
    "        del x_new, vx_new, tx_new\n",
    "        \n",
    "        # 定義transform\n",
    "        # training 時做 data augmentation\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((img_size, img_size)),  # 縮放\n",
    "            transforms.RandomRotation(degrees=30),  # 旋轉\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 平移\n",
    "            transforms.RandomCrop(input_size),  # 隨機裁剪\n",
    "            transforms.RandomHorizontalFlip(),  # 水平翻轉\n",
    "            transforms.ToTensor(),  # 轉換為Tensor\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 標準化\n",
    "\n",
    "        ])\n",
    "        # testing 時不需做 data augmentation\n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((img_size, img_size)),  # 縮放\n",
    "            transforms.CenterCrop(input_size),  # 中心裁剪\n",
    "            transforms.ToTensor(),  # 轉換為Tensor\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 標準化\n",
    "        ])\n",
    "        # data loader\n",
    "        train_set = ImgDataset(x_resize, y, train_transform)\n",
    "        val_set = ImgDataset(vx_resize, vy, test_transform)\n",
    "        test_set = ImgDataset(tx_resize, ty, test_transform)\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, worker_init_fn=lambda _: np.random.seed(42), num_workers=4)\n",
    "        val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "        test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "        del x_resize, vx_resize, tx_resize\n",
    "        \n",
    "        \n",
    "        \n",
    "        for model_name in ['DynamicCNN', 'base_model']:\n",
    "            # create model\n",
    "            model = create_model(model_name, nof_kernels=nof_kernels).to(device)\n",
    "            # 測FLOPs、params\n",
    "            # 创建输入张量\n",
    "            inputs = torch.randn(1, 3, input_size, input_size)\n",
    "            calc_complexity(model, inputs.to(device))\n",
    "            \n",
    "            \n",
    "            n_train = train_set.__len__()\n",
    "            n_val = val_set.__len__()\n",
    "            n_test = test_set.__len__()\n",
    "            train(model, train_loader, val_loader, eval_time, num_epoch, n_train, n_val, temperature, lr, device)\n",
    "            test(model, test_loader, n_test, temperature, device)\n",
    "            \n",
    "            del model\n",
    "            gc.collect()\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "experiment_3_1_1(nof_kernels=7)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efc4356-5a55-4203-8cf7-3d98d78cb264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f852fa8f-5fa2-4856-a2d2-3b169ed78e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dl_hw1",
   "language": "python",
   "name": "dl_hw1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
