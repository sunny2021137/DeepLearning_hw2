{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b00d1bd1-e2e0-4f71-a873-abe8c8b03b1f",
   "metadata": {
    "id": "b00d1bd1-e2e0-4f71-a873-abe8c8b03b1f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p76121194/miniconda3/envs/dl_hw1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import tqdm\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torch.nn import init\n",
    "from torch.nn.modules.utils import _pair\n",
    "import math\n",
    "from timm.models.layers import to_2tuple, trunc_normal_, DropPath\n",
    "import einops\n",
    "from thop import profile, clever_format\n",
    "import gc\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92033f7e-66f3-4c7d-bcee-0b9feb956ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a37727bf-f8ef-49e8-b1d1-c1b9ec5090ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAttention(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, n_heads, n_head_channels, n_groups,\n",
    "        attn_drop, proj_drop, stride, ksize\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.n_head_channels = n_head_channels\n",
    "        self.scale = self.n_head_channels ** -0.5\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        self.nc = n_head_channels * n_heads\n",
    "        self.n_groups = n_groups\n",
    "        # 每個group幾個channel\n",
    "        self.n_group_channels = self.nc // self.n_groups\n",
    "        self.ksize = ksize\n",
    "        # kernel_size\n",
    "        kk = self.ksize\n",
    "        pad_size = kk // 2 if kk != stride else 0\n",
    "\n",
    "        self.conv_offset = nn.Sequential(\n",
    "            nn.Conv2d(self.n_group_channels, self.n_group_channels, kk, stride, pad_size, groups=self.n_group_channels),\n",
    "            LayerNormProxy(self.n_group_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(self.n_group_channels, 2, 1, 1, 0, bias=False)\n",
    "        )\n",
    "\n",
    "        self.proj_q = nn.Conv2d(\n",
    "            self.nc, self.nc,\n",
    "            kernel_size=1, stride=1, padding=0\n",
    "        )\n",
    "\n",
    "        self.proj_k = nn.Conv2d(\n",
    "            self.nc, self.nc,\n",
    "            kernel_size=1, stride=1, padding=0\n",
    "        )\n",
    "\n",
    "        self.proj_v = nn.Conv2d(\n",
    "            self.nc, self.nc,\n",
    "            kernel_size=1, stride=1, padding=0\n",
    "        )\n",
    "\n",
    "        self.proj_out = nn.Conv2d(\n",
    "            self.nc, self.nc,\n",
    "            kernel_size=1, stride=1, padding=0\n",
    "        )\n",
    "\n",
    "        self.proj_drop = nn.Dropout(proj_drop, inplace=True)\n",
    "        self.attn_drop = nn.Dropout(attn_drop, inplace=True)\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _get_ref_points(self, H_key, W_key, B, dtype, device):\n",
    "        # 產生值為-1~1的網格\n",
    "        ref_y, ref_x = torch.meshgrid(\n",
    "            torch.linspace(0.5, H_key - 0.5, H_key, dtype=dtype, device=device),\n",
    "            torch.linspace(0.5, W_key - 0.5, W_key, dtype=dtype, device=device),\n",
    "            indexing='ij'\n",
    "        )\n",
    "        ref = torch.stack((ref_y, ref_x), -1)\n",
    "        ref[..., 1].div_(W_key - 1.0).mul_(2.0).sub_(1.0)\n",
    "        ref[..., 0].div_(H_key - 1.0).mul_(2.0).sub_(1.0)\n",
    "        ref = ref[None, ...].expand(B * self.n_groups, -1, -1, -1) # B * g H W 2\n",
    "\n",
    "        return ref\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        B, C, H, W = x.size()\n",
    "        dtype, device = x.dtype, x.device\n",
    "        # q\n",
    "        q = self.proj_q(x)\n",
    "        # offsets\n",
    "        q_off = einops.rearrange(q, 'b (g c) h w -> (b g) c h w', g=self.n_groups, c=self.n_group_channels) #(B*n_groups, new_channel#, h, w)\n",
    "        offset = self.conv_offset(q_off).contiguous()  # (B, 2, h/stride, w/stride) \n",
    "        \n",
    "        Hk, Wk = offset.size(2), offset.size(3)\n",
    "        n_sample = Hk * Wk\n",
    "\n",
    "\n",
    "        offset = einops.rearrange(offset, 'b p h w -> b h w p') ## (B, h/stride, w/stride, 2) \n",
    "        # 採樣點\n",
    "        reference = self._get_ref_points(Hk, Wk, B, dtype, device)\n",
    "        \n",
    "        # 變形採樣點\n",
    "        pos = (offset + reference).clamp(-1., +1.)\n",
    "\n",
    "        # 雙線性差值\n",
    "        x_sampled = F.grid_sample(\n",
    "                input=x.reshape(B * self.n_groups, self.n_group_channels, H, W), \n",
    "                grid=pos[..., (1, 0)], # y, x -> x, y\n",
    "                mode='bilinear', align_corners=True) # B * g, Cg, Hg, Wg\n",
    "                \n",
    "        # 變形採樣後的x(x~)\n",
    "        x_sampled = x_sampled.reshape(B, C, 1, n_sample)\n",
    "\n",
    "        q = q.reshape(B * self.n_heads, self.n_head_channels, H * W)\n",
    "        k = self.proj_k(x_sampled).reshape(B * self.n_heads, self.n_head_channels, n_sample)\n",
    "        v = self.proj_v(x_sampled).reshape(B * self.n_heads, self.n_head_channels, n_sample)\n",
    "\n",
    "        # att\n",
    "        attn = torch.einsum('b c m, b c n -> b m n', q, k) # (B * n_heads, H*W, n_sample)\n",
    "        attn = attn.mul(self.scale)\n",
    "        attn = F.softmax(attn, dim=2)\n",
    "        attn = self.attn_drop(attn)\n",
    "        out = torch.einsum('b m n, b c n -> b c m', attn, v) #(B * n_heads, n_head_channels, H*W)\n",
    "\n",
    "        \n",
    "        out = out.reshape(B, C, H, W)\n",
    "        # Wo\n",
    "        y = self.proj_drop(self.proj_out(out))\n",
    "\n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74b226a1-1067-4780-af7d-654a2d474fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormProxy(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = einops.rearrange(x, 'b c h w -> b h w c')\n",
    "        x = self.norm(x)\n",
    "        return einops.rearrange(x, 'b h w c -> b c h w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f32bac3a-b23a-4a9e-ab9c-96edcc39ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=50):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, 1, 1), # [32, 128, 128]\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [32, 64, 64]\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, 1, 1), # [64, 64, 64]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [64, 32, 32]\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, 1), # [128, 32, 32]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [128, 16, 16]\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, 1, 1), # [256, 16, 16]\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),       # [256, 8, 8]\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*8*8, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa0efb4e-7084-44a6-b41c-db63c48f0887",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATCNN(nn.Module):\n",
    "    def __init__(self, num_classes=50, n_heads=4):\n",
    "        super(DATCNN, self).__init__()\n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, 1, 1), # [32, 128, 128]\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [32, 64, 64]\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, 1, 1), # [64, 64, 64]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [64, 32, 32]\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, 1), # [128, 32, 32]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [128, 16, 16]\n",
    "        )\n",
    "        n_heads = n_heads\n",
    "        self.dat = DAttention(n_heads=n_heads, n_head_channels=128//n_heads, n_groups=2, attn_drop=0, proj_drop=0, stride=1, ksize=3)\n",
    "        self.norm = LayerNormProxy(128)\n",
    "        self.nn2 = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128*8*8, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = self.norm(self.dat(out)) + out\n",
    "        out = self.nn2(out)\n",
    "        out = out.contiguous().view(out.size()[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1411f880-1ba5-4590-8b0e-2664d08b8d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_complexity(model, inputs):\n",
    "    # 计算FLOPs和参数量\n",
    "    flops, params = profile(model, inputs=(inputs,))\n",
    "    flops, params = clever_format([flops, params], \"%.3f\")\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274ca17c-2a38-4461-b261-cdcb8c1d161e",
   "metadata": {
    "id": "274ca17c-2a38-4461-b261-cdcb8c1d161e"
   },
   "outputs": [],
   "source": [
    "def load_img(f):\n",
    "    shapes = []\n",
    "    f=open(f)\n",
    "    lines=f.readlines()\n",
    "    imgs, lab=[], []\n",
    "    for i in range(len(lines)):\n",
    "        fn, label = lines[i].split(' ')\n",
    "        im1=cv2.imread(fn)\n",
    "\n",
    "        if im1.shape[2] not in shapes:\n",
    "            shapes.append(im1.shape[2])\n",
    "        # im1=cv2.resize(im1, (img_size,img_size))\n",
    "        # im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # im1 = preprocessing(im1, op_list)\n",
    "        # vec = np.reshape(im1, [-1])\n",
    "\n",
    "        imgs.append(im1)\n",
    "        lab.append(int(label))\n",
    "        \n",
    "    print(i)\n",
    "\n",
    "    # imgs= np.asarray(imgs, np.uint8)\n",
    "    lab= np.asarray(lab, np.uint8)\n",
    "    # print(shapes)\n",
    "    return imgs, lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef833888-8ef2-4bbf-b31e-9251790fff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name, n_heads=4, stride=1, ksize=3):\n",
    "    model = None\n",
    "    if model_name == \"DATCNN\":\n",
    "        model = DATCNN(num_classes=50, n_heads=n_heads)\n",
    "    elif model_name == \"SimpleCNN\":\n",
    "        model = SimpleCNN(num_classes=50)\n",
    "    elif model_name == \"ResNet34\":\n",
    "        model = models.resnet34()\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, 50)  # 设置最后一层输出为分类数目\n",
    "    else:\n",
    "        print(error)\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32f40359-f0d9-43d0-b155-b9e1982b0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, x, y=None, transform=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        if y is not None:\n",
    "            self.y = torch.LongTensor(y)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, index):\n",
    "        X = self.x[index]\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        if self.y is not None:\n",
    "            Y = self.y[index]\n",
    "            return X, Y\n",
    "        else:\n",
    "            return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57c6b7f8-03b1-4a1d-9f4b-0836972c4b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, eval_time, num_epoch, n_train, n_val, lr, device):\n",
    "    # print(\"--4--\")\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # print(\"device\", device)\n",
    "    # model = model.to(device)\n",
    "\n",
    "    loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr) # optimizer 使用 Adam\n",
    "\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        print(epoch)\n",
    "        \n",
    "        epoch_start_time = time.time()\n",
    "        train_acc = 0.0\n",
    "        train_loss = 0.0\n",
    "        val_acc = 0.0\n",
    "        val_loss = 0.0\n",
    "\n",
    "        model.train() # 確保 model 是在 train model (開啟 Dropout 等...)\n",
    "        for i, data in enumerate(train_loader):\n",
    "            optimizer.zero_grad() # 用 optimizer 將 model 參數的 gradient 歸零\n",
    "            \n",
    "            train_pred = model(data[0].to(device)) # 利用 model 得到預測的機率分佈 這邊實際上就是去呼叫 model 的 forward 函數\n",
    "            batch_loss = loss(train_pred, data[1].to(device)) # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\n",
    "            batch_loss.backward() # 利用 back propagation 算出每個參數的 gradient\n",
    "            optimizer.step() # 以 optimizer 用 gradient 更新參數值\n",
    "\n",
    "            train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "            train_loss += batch_loss.item()\n",
    "\n",
    "        if epoch % eval_time == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(val_loader):\n",
    "                    val_pred = model(data[0].to(device))\n",
    "                    batch_loss = loss(val_pred, data[1].to(device))\n",
    "\n",
    "                    val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "                    val_loss += batch_loss.item()\n",
    "\n",
    "                # 將結果 print 出來\n",
    "                print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n",
    "                    (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n",
    "                     train_acc/n_train, train_loss/n_train, val_acc/n_val, val_loss/n_val))\n",
    "\n",
    "               \n",
    "                print(\"Train/epoch\",  epoch)\n",
    "                print(\"Train/acc\", train_acc/n_train)\n",
    "                print(\"Train/loss\", train_loss/n_train)\n",
    "                print(\"Val/epoch\", epoch)\n",
    "                print(\"Val/acc\", val_acc/n_val)\n",
    "                print(\"Val/loss\", val_loss/n_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a899aaf-3990-4e48-9c70-971f7f8677c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, n_test, device):\n",
    "    model.eval()\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # print(\"device\", device)\n",
    "    # model = model.to(device)\n",
    "    loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\n",
    "    \n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    test_acc = 0.0\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            test_pred = model(data[0].to(device))\n",
    "            batch_loss = loss(test_pred, data[1].to(device))\n",
    "            test_loss += batch_loss.item()\n",
    "\n",
    "            _, preds = torch.max(test_pred, 1)\n",
    "            all_labels.extend(data[1].cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "        recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "        print(\"--------Test result-------------\")\n",
    "        print(f'Accuracy: {accuracy:.4f}')\n",
    "        print(f'Precision: {precision:.4f}')\n",
    "        print(f'Recall: {recall:.4f}')\n",
    "        print(f'F1-score: {f1:.4f}')\n",
    "        print(f'Loss: {test_loss//n_test:.4f}')\n",
    "        print(\"--------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32dc6ad-c90e-4745-a3c0-91330e81397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nof_heads\n",
    "def experiment_5_1():\n",
    "    # 超參數\n",
    "    #############\n",
    "    eval_time = 1\n",
    "    num_epoch = 30\n",
    "    num_classes = 50\n",
    "    img_size = 144\n",
    "    input_size = 128\n",
    "    batch_size = 128\n",
    "    lr = 0.001\n",
    "    model_name= \"DATCNN\"\n",
    "    stride=4\n",
    "    ksize=7\n",
    "    \n",
    "    #############\n",
    "    set_seed(42)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    x, y = load_img('train.txt')\n",
    "    vx, vy = load_img('val.txt')\n",
    "    tx, ty = load_img('test.txt')\n",
    "    print(\"--1--\")\n",
    "    # 定義transform\n",
    "    # training 時做 data augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((img_size, img_size)),  # 縮放\n",
    "        transforms.RandomRotation(degrees=30),  # 旋轉\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 平移\n",
    "        transforms.RandomCrop(input_size),  # 隨機裁剪\n",
    "        transforms.RandomHorizontalFlip(),  # 水平翻轉\n",
    "        transforms.ToTensor(),  # 轉換為Tensor\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 標準化\n",
    "\n",
    "    ])\n",
    "    # testing 時不需做 data augmentation\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((img_size, img_size)),  # 縮放\n",
    "        transforms.CenterCrop(input_size),  # 中心裁剪\n",
    "        transforms.ToTensor(),  # 轉換為Tensor\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 標準化\n",
    "    ])\n",
    "    # data loader\n",
    "    train_set = ImgDataset(x, y, train_transform)\n",
    "    val_set = ImgDataset(vx, vy, test_transform)\n",
    "    test_set = ImgDataset(tx, ty, test_transform)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, worker_init_fn=lambda _: np.random.seed(42), num_workers=4)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    del x, vx, tx\n",
    "\n",
    "    \n",
    "    \n",
    "    # n_heads要能被128整除\n",
    "    for n_heads in [1, 2, 4, 8]:\n",
    "        print(\"-----number of heads = \"+str(n_heads)+\"-----\")\n",
    "        # create model\n",
    "        model = create_model(model_name, n_heads=n_heads, stride=stride, ksize=ksize).to(device)\n",
    "        # 測FLOPs、params\n",
    "        # 创建输入张量\n",
    "        inputs = torch.randn(1, 3, input_size, input_size)\n",
    "        calc_complexity(model, inputs.to(device))\n",
    "        \n",
    "        \n",
    "        n_train = train_set.__len__()\n",
    "        n_val = val_set.__len__()\n",
    "        n_test = test_set.__len__()\n",
    "        train(model, train_loader, val_loader, eval_time, num_epoch, n_train, n_val, lr, device)\n",
    "        test(model, test_loader, n_test, device)\n",
    "       \n",
    "        del model\n",
    "        gc.collect()\n",
    "    \n",
    "        \n",
    "        \n",
    "experiment_5_1()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb124cf9-2e46-4b52-a38c-3638dc0d8171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nof_heads\n",
    "def experiment_5_2(n_heads):\n",
    "    # 超參數\n",
    "    #############\n",
    "    eval_time = 1\n",
    "    num_epoch = 30\n",
    "    num_classes = 50\n",
    "    img_size = 144\n",
    "    input_size = 128\n",
    "    batch_size = 128\n",
    "    lr = 0.001\n",
    "    model_name= \"DATCNN\"\n",
    "    n_heads = n_heads\n",
    "    #############\n",
    "    set_seed(42)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    x, y = load_img('train.txt')\n",
    "    vx, vy = load_img('val.txt')\n",
    "    tx, ty = load_img('test.txt')\n",
    "    print(\"--1--\")\n",
    "    # 定義transform\n",
    "    # training 時做 data augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((img_size, img_size)),  # 縮放\n",
    "        transforms.RandomRotation(degrees=30),  # 旋轉\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 平移\n",
    "        transforms.RandomCrop(input_size),  # 隨機裁剪\n",
    "        transforms.RandomHorizontalFlip(),  # 水平翻轉\n",
    "        transforms.ToTensor(),  # 轉換為Tensor\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 標準化\n",
    "\n",
    "    ])\n",
    "    # testing 時不需做 data augmentation\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((img_size, img_size)),  # 縮放\n",
    "        transforms.CenterCrop(input_size),  # 中心裁剪\n",
    "        transforms.ToTensor(),  # 轉換為Tensor\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 標準化\n",
    "    ])\n",
    "    # data loader\n",
    "    train_set = ImgDataset(x, y, train_transform)\n",
    "    val_set = ImgDataset(vx, vy, test_transform)\n",
    "    test_set = ImgDataset(tx, ty, test_transform)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, worker_init_fn=lambda _: np.random.seed(42), num_workers=4)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    del x, vx, tx\n",
    "\n",
    "    \n",
    "   \n",
    "    # n_heads要能被128整除\n",
    "    strides = [8, 4, 2, 1]\n",
    "    ksizes= [9, 7, 5, 3]\n",
    "    for stride, ksize in zip(strides, ksizes):\n",
    "        print(\"----- (stride, ksize) = (\"+str(stride)+\", \"+str(ksize)+\") -----\")\n",
    "        # create model\n",
    "        model = create_model(model_name, n_heads=n_heads, stride=stride, ksize=ksize).to(device)\n",
    "        # 測FLOPs、params\n",
    "        # 创建输入张量\n",
    "        inputs = torch.randn(1, 3, input_size, input_size)\n",
    "        calc_complexity(model, inputs.to(device))\n",
    "        \n",
    "        \n",
    "        n_train = train_set.__len__()\n",
    "        n_val = val_set.__len__()\n",
    "        n_test = test_set.__len__()\n",
    "        train(model, train_loader, val_loader, eval_time, num_epoch, n_train, n_val, lr, device)\n",
    "        test(model, test_loader, n_test, device)\n",
    "        del model\n",
    "        gc.collect()\n",
    "        \n",
    "        \n",
    "experiment_5_2(n_heads=4)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80a1636-af7a-4185-b0ef-8057ff55c565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no self-attention\n",
    "def experiment_3_1(n_heads, stride, ksize):\n",
    "    # 超參數\n",
    "    #############\n",
    "    eval_time = 1\n",
    "    num_epoch = 30\n",
    "    num_classes = 50\n",
    "    img_size = 144\n",
    "    input_size = 128\n",
    "    batch_size = 128\n",
    "    lr = 0.001\n",
    "    n_heads=n_heads\n",
    "    stride=stride\n",
    "    ksize=ksize\n",
    "    #############\n",
    "    set_seed(42)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    x, y = load_img('train.txt')\n",
    "    vx, vy = load_img('val.txt')\n",
    "    tx, ty = load_img('test.txt')\n",
    "    print(\"--1--\")\n",
    "    # 定義transform\n",
    "    # training 時做 data augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((img_size, img_size)),  # 縮放\n",
    "        transforms.RandomRotation(degrees=30),  # 旋轉\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 平移\n",
    "        transforms.RandomCrop(input_size),  # 隨機裁剪\n",
    "        transforms.RandomHorizontalFlip(),  # 水平翻轉\n",
    "        transforms.ToTensor(),  # 轉換為Tensor\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 標準化\n",
    "\n",
    "    ])\n",
    "    # testing 時不需做 data augmentation\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((img_size, img_size)),  # 縮放\n",
    "        transforms.CenterCrop(input_size),  # 中心裁剪\n",
    "        transforms.ToTensor(),  # 轉換為Tensor\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 標準化\n",
    "    ])\n",
    "    # data loader\n",
    "    train_set = ImgDataset(x, y, train_transform)\n",
    "    val_set = ImgDataset(vx, vy, test_transform)\n",
    "    test_set = ImgDataset(tx, ty, test_transform)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, worker_init_fn=lambda _: np.random.seed(42), num_workers=4)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    del x, vx, tx\n",
    "\n",
    "    \n",
    "    \n",
    "    # n_heads要能被128整除\n",
    "    for model_name in [\"ResNet34\", \"DATCNN\", \"SimpleCNN\"]:\n",
    "        print(\"-----model = \"+model_name+\"-----\")\n",
    "        # create model\n",
    "        model = create_model(model_name, n_heads=n_heads, stride=stride, ksize=ksize).to(device)\n",
    "        # 測FLOPs、params\n",
    "        # 创建输入张量\n",
    "        inputs = torch.randn(1, 3, input_size, input_size)\n",
    "        calc_complexity(model, inputs.to(device))\n",
    "        \n",
    "        n_train = train_set.__len__()\n",
    "        n_val = val_set.__len__()\n",
    "        n_test = test_set.__len__()\n",
    "        train(model, train_loader, val_loader, eval_time, num_epoch, n_train, n_val, lr, device)\n",
    "        test(model, test_loader, n_test, device)\n",
    "        del model\n",
    "        gc.collect()\n",
    "    \n",
    "        \n",
    "        \n",
    "experiment_3_1(n_heads=8, stride=4, ksize=7)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec7b664-028e-427a-b4b8-d894f8adf493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dl_hw1",
   "language": "python",
   "name": "dl_hw1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
